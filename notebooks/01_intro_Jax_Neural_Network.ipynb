{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXUiQXAcJZ0c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igiYLCyoJ3--"
   },
   "source": [
    "# Redes Neuronales con JAX\n",
    "\n",
    "* En este notebook vamos a crear una red neuronal multicapa con JAX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DIhxcosTKAeo"
   },
   "outputs": [],
   "source": [
    "from jax import numpy as jnp\n",
    "from jax import grad\n",
    "from jax import jacobian\n",
    "from jax import random\n",
    "from jax import vmap\n",
    "from jax import value_and_grad\n",
    "from jax import jit\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRFYhjZPeRwo"
   },
   "source": [
    "## Implementando una red neuronal tipo básica\n",
    "\n",
    "* Vamos a tratar de implementar la red directamente sin ningún tipo de abstracción.\n",
    "* El objetivo es implementar las funciones necesarias para poder calcularles el gradiente y después de eso hacer la actualización de pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "166Kphw2eX8v"
   },
   "outputs": [],
   "source": [
    "def predict(W,x):\n",
    "  # Layer 1\n",
    "  W1 = W['1']\n",
    "  z1 = jnp.dot(x, jnp.transpose(W1))\n",
    "  y1 = jnp.tanh(z1)\n",
    "\n",
    "  # Output layer\n",
    "  W2 = W['2']\n",
    "  z2 = jnp.dot(y1, jnp.transpose(W2))\n",
    "  y2 = jnp.tanh(z2)\n",
    "  return y2\n",
    "\n",
    "def loss(W, x, y):\n",
    "  # Foward pass\n",
    "  yp = predict(W, x)\n",
    "\n",
    "  # Loss\n",
    "  loss = jnp.sum(jnp.pow(yp - y, 2))/y.shape[0]\n",
    "\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1721104936894,
     "user": {
      "displayName": "Angel Alejandro Maldonado Ramírez",
      "userId": "05170948916545730550"
     },
     "user_tz": 360
    },
    "id": "xe9c8X_nkg_J",
    "outputId": "c606ee67-451b-49c7-8678-b993e7d1ba98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss inicial:  2.505769\n",
      "Predicciones iniciales:  [[0.9933537 ]\n",
      " [0.91059923]\n",
      " [0.96643686]]\n"
     ]
    }
   ],
   "source": [
    "# Definir parametros\n",
    "x = jnp.array([[1.0, 3.5],[-0.5, 0.6], [-0.5, 1.3]])\n",
    "#y = jnp.array([[1],[0],[0]])\n",
    "y = jnp.array([[1],[-1],[-1]])\n",
    "n_neurons = 4\n",
    "n_features = x.shape[1]\n",
    "key = random.key(10)\n",
    "\n",
    "key, key_w1, key_w2 = random.split(key, 3)\n",
    "W1 = random.normal(key_w1, (n_neurons, n_features))\n",
    "W2 = random.normal(key_w2, (1, n_neurons))\n",
    "W = {'1': W1, '2': W2}\n",
    "\n",
    "initial_loss = loss(W, x,y)\n",
    "print(\"Loss inicial: \", initial_loss)\n",
    "\n",
    "yp = predict(W,x)\n",
    "print(\"Predicciones iniciales: \", yp)\n",
    "#x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MNUlbeGwwuGd"
   },
   "outputs": [],
   "source": [
    "# Calculamos la loss y el gradiente al mismo tiempo\n",
    "val_grad_loss = value_and_grad(loss, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 562,
     "status": "ok",
     "timestamp": 1721104944302,
     "user": {
      "displayName": "Angel Alejandro Maldonado Ramírez",
      "userId": "05170948916545730550"
     },
     "user_tz": 360
    },
    "id": "roM7k9zxy_GY",
    "outputId": "8afb0a91-814f-4981-9f63-36ddc2411373"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca 0\n",
      "Loss:  2.505769\n",
      "Epoca 1\n",
      "Loss:  2.3822467\n",
      "Epoca 2\n",
      "Loss:  1.9204383\n",
      "Epoca 3\n",
      "Loss:  1.3888327\n",
      "Epoca 4\n",
      "Loss:  0.34902894\n",
      "Epoca 5\n",
      "Loss:  0.14577721\n",
      "Epoca 6\n",
      "Loss:  0.100438915\n",
      "Epoca 7\n",
      "Loss:  0.08674523\n",
      "Epoca 8\n",
      "Loss:  0.035762027\n",
      "Epoca 9\n",
      "Loss:  0.029983804\n",
      "Epoca 10\n",
      "Loss:  0.026187697\n",
      "Epoca 11\n",
      "Loss:  0.023223206\n",
      "Epoca 12\n",
      "Loss:  0.020836145\n",
      "Epoca 13\n",
      "Loss:  0.018873692\n",
      "Epoca 14\n",
      "Loss:  0.017232819\n",
      "Epoca 15\n",
      "Loss:  0.015841307\n",
      "Epoca 16\n",
      "Loss:  0.014647047\n",
      "Epoca 17\n",
      "Loss:  0.0136114685\n",
      "Epoca 18\n",
      "Loss:  0.012705368\n",
      "Epoca 19\n",
      "Loss:  0.011906266\n",
      "Epoca 20\n",
      "Loss:  0.011196614\n",
      "Epoca 21\n",
      "Loss:  0.0105624525\n",
      "Epoca 22\n",
      "Loss:  0.009992548\n",
      "Epoca 23\n",
      "Loss:  0.009477801\n",
      "Epoca 24\n",
      "Loss:  0.009010741\n",
      "Epoca 25\n",
      "Loss:  0.0085851485\n",
      "Epoca 26\n",
      "Loss:  0.008195867\n",
      "Epoca 27\n",
      "Loss:  0.007838518\n",
      "Epoca 28\n",
      "Loss:  0.0075094122\n",
      "Epoca 29\n",
      "Loss:  0.007205428\n"
     ]
    }
   ],
   "source": [
    "# aplicamos un ciclo de entrenamiento\n",
    "epochs = 30\n",
    "learning_rate = 0.1\n",
    "for i in range(epochs):\n",
    "  print(f\"Epoca {i}\")\n",
    "  # Calcular gradiente\n",
    "  loss_val, grad_w = val_grad_loss(W, x, y)\n",
    "  print(\"Loss: \", loss_val)\n",
    "\n",
    "  # Actualizar pesos\n",
    "  W['1'] = W['1'] - learning_rate * grad_w['1']\n",
    "  W['2'] = W['2'] - learning_rate * grad_w['2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1721104947857,
     "user": {
      "displayName": "Angel Alejandro Maldonado Ramírez",
      "userId": "05170948916545730550"
     },
     "user_tz": 360
    },
    "id": "NDK1H0gbz_3r",
    "outputId": "9f3e4489-28c9-4d46-8649-2efec4996cd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones:  [[ 0.93151844]\n",
      " [-0.9052495 ]\n",
      " [-0.9157144 ]]\n"
     ]
    }
   ],
   "source": [
    "# Calculamos las predicciones\n",
    "yp = predict(W, x)\n",
    "print(\"Predicciones: \", yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zbo9nps_1PPY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GHK4hJB2bGW"
   },
   "source": [
    "## Implementar red neuronal tipo Scikit-learn\n",
    "\n",
    "* Vamos a tratar de abstraer la construcción de una red neuronal para que podamos definir tamaños arbitrarios.\n",
    "* La red se va a definir de manera similar a como se realiza en Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pnALyXMc2iJz"
   },
   "outputs": [],
   "source": [
    "# vamos a encapsular toda la lógica en una clase de Python.\n",
    "class MLPClassifier():\n",
    "  def __init__(self, units, epochs=10, lr=0.01, binary=True, n_classes=2,seed=0):\n",
    "    self.key = random.key(seed)\n",
    "    self.epochs = epochs\n",
    "    self.lr = lr\n",
    "    self.W = dict()\n",
    "    if binary:\n",
    "      self.units = units + [1]\n",
    "    else:\n",
    "      self.units = units + [n_classes]\n",
    "\n",
    "  def forward(self, W, X):\n",
    "    n_layers = len(self.units)\n",
    "    output = X\n",
    "    for i in range(n_layers):\n",
    "      #W = W[i]\n",
    "      z = jnp.dot(output, jnp.transpose(W[i]))\n",
    "      output = jnp.tanh(z)\n",
    "    return output\n",
    "\n",
    "  def predict(self, X):\n",
    "    n_layers = len(self.units)\n",
    "    output = X\n",
    "    for i in range(n_layers):\n",
    "      #W = W[i]\n",
    "      z = jnp.dot(output, jnp.transpose(self.W[i]))\n",
    "      output = jnp.tanh(z)\n",
    "    return output\n",
    "\n",
    "  def loss(self, W, X, y):\n",
    "    yp = self.forward(W, X)\n",
    "    l = jnp.sum(jnp.pow(yp - y, 2))/y.shape[0]\n",
    "    return l\n",
    "\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    n_features = X.shape[1]\n",
    "    n_samples = X.shape[0]\n",
    "    n_layers = len(self.units) # +1 para tomar en cuenta la capa de salida\n",
    "\n",
    "    # Creamos las matrices de pesos.\n",
    "    keys = random.split(self.key, n_layers)\n",
    "    W = dict()\n",
    "    for i in range(n_layers):\n",
    "      n_units = self.units[i]\n",
    "      W[i] = random.normal(keys[i], (n_units, n_features))\n",
    "      n_features = self.units[i]\n",
    "\n",
    "    # calculamos el gradiente\n",
    "    val_grad_loss = jit(value_and_grad(self.loss, 0))\n",
    "\n",
    "    # Entrenamos la red\n",
    "    loss_val, grad_val = val_grad_loss(W, X, y)\n",
    "    print(f\"Initial loss: {loss_val}\")\n",
    "    for ep in range(self.epochs):\n",
    "      # Calcular gradiente\n",
    "      loss_val, grad_w = val_grad_loss(W, X, y)\n",
    "      print(f\"Epoch: {ep} - Loss: {loss_val}\")\n",
    "\n",
    "      # Actualizar pesos\n",
    "      for i in range(n_layers):\n",
    "        W[i] = W[i] - self.lr*grad_w[i]\n",
    "    # Guardamos pesos\n",
    "    self.W = W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hHz3WAZlU4Zr"
   },
   "outputs": [],
   "source": [
    "# Preparamos datos de entrada\n",
    "X = jnp.array([[1.0, 3.5],[-0.5, 0.6], [-0.5, 1.3]])\n",
    "#y = jnp.array([[1],[0],[0]])\n",
    "y = jnp.array([[1],[0],[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 968,
     "status": "ok",
     "timestamp": 1721180480413,
     "user": {
      "displayName": "Angel Alejandro Maldonado Ramírez",
      "userId": "05170948916545730550"
     },
     "user_tz": 360
    },
    "id": "z9YJPPdYVFs1",
    "outputId": "58d2cc2e-9ec9-4cbc-8c95-cbfeab7be940"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 2.2084829807281494\n",
      "Epoch: 0 - Loss: 2.2084829807281494\n",
      "Epoch: 1 - Loss: 0.40662333369255066\n",
      "Epoch: 2 - Loss: 0.15469112992286682\n",
      "Epoch: 3 - Loss: 0.0693286806344986\n",
      "Epoch: 4 - Loss: 0.04397426173090935\n",
      "Epoch: 5 - Loss: 0.0320630706846714\n",
      "Epoch: 6 - Loss: 0.025168560445308685\n",
      "Epoch: 7 - Loss: 0.020678821951150894\n",
      "Epoch: 8 - Loss: 0.017525091767311096\n",
      "Epoch: 9 - Loss: 0.015190052799880505\n",
      "Epoch: 10 - Loss: 0.013392775319516659\n",
      "Epoch: 11 - Loss: 0.011967720463871956\n",
      "Epoch: 12 - Loss: 0.010810835286974907\n",
      "Epoch: 13 - Loss: 0.009853530675172806\n",
      "Epoch: 14 - Loss: 0.009048725478351116\n",
      "Epoch: 15 - Loss: 0.008362996391952038\n",
      "Epoch: 16 - Loss: 0.0077720386907458305\n",
      "Epoch: 17 - Loss: 0.00725766085088253\n",
      "Epoch: 18 - Loss: 0.006806101184338331\n",
      "Epoch: 19 - Loss: 0.0064066024497151375\n",
      "Epoch: 20 - Loss: 0.0060507929883897305\n",
      "Epoch: 21 - Loss: 0.005731978453695774\n",
      "Epoch: 22 - Loss: 0.005444720387458801\n",
      "Epoch: 23 - Loss: 0.005184633191674948\n",
      "Epoch: 24 - Loss: 0.004948069341480732\n",
      "Epoch: 25 - Loss: 0.004732018802314997\n",
      "Epoch: 26 - Loss: 0.004533970728516579\n",
      "Epoch: 27 - Loss: 0.0043517714366316795\n",
      "Epoch: 28 - Loss: 0.004183634649962187\n",
      "Epoch: 29 - Loss: 0.004027983173727989\n"
     ]
    }
   ],
   "source": [
    "# Creamos y entrenamos modelo\n",
    "model = MLPClassifier([16,16,8], lr=0.1, epochs=30)\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 463,
     "status": "ok",
     "timestamp": 1721180485673,
     "user": {
      "displayName": "Angel Alejandro Maldonado Ramírez",
      "userId": "05170948916545730550"
     },
     "user_tz": 360
    },
    "id": "0apBq4PeVH-v",
    "outputId": "d1e4a584-e245-4505-a3e2-c9355a95467d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 0.9507567 ],\n",
       "       [-0.9378166 ],\n",
       "       [-0.92679554]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp = model.predict(X)\n",
    "yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1721180822283,
     "user": {
      "displayName": "Angel Alejandro Maldonado Ramírez",
      "userId": "05170948916545730550"
     },
     "user_tz": 360
    },
    "id": "AdEOH6GEVryT",
    "outputId": "773a93ed-d830-4c02-c2f6-0e68ae26aba1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size 0th layer: 720\n",
      "Size 1th layer: 720\n",
      "Size 2th layer: 720\n",
      "Size 3th layer: 720\n"
     ]
    }
   ],
   "source": [
    "sys.getsizeof(model.W)\n",
    "for i in range(len(model.W)):\n",
    "  #print(f\"Size {i}th layer: {model.W[i].shape}\")\n",
    "  print(f\"Size {i}th layer: {sys.getsizeof(model.W[i])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyIS4mXpX3ux"
   },
   "source": [
    "## Siguientes pasos\n",
    "\n",
    "* Agregarle bias.\n",
    "* Agregarle otras funciones de activación\n",
    "* Agregarle otras funciones de pérdida\n",
    "* Probar para un problema multiclase real (por ejemplo, mnist)\n",
    "* Comparar tiempo de entrenamiento vs scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Q9WOUqfV0mw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMUTiWWiDGU+d0Uh8wCI7pi",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

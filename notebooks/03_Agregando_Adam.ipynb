{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNgtIvSJVEQKSBXcAM13qdQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"2m-BCdlpeKax"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["# Agregando Adam\n","\n","\n","* En el notebook pasado vimos como se batalla para ajustar los hiperparametros de una red neuronal para problemas más complejos.\n","* En este notebook nos enfocaremos en agregar el método de optimización de pesos, Adam."],"metadata":{"id":"_YK179_5eRHd"}},{"cell_type":"code","source":["# Importamos librerias\n","from jax import numpy as jnp\n","from jax import grad\n","from jax import jacobian\n","from jax import random\n","from jax import vmap\n","from jax import value_and_grad\n","from jax import jit\n","from jax import nn\n","from jax import lax\n","import sys\n","import numpy as np"],"metadata":{"id":"dUmB3IqLeeiV","executionInfo":{"status":"ok","timestamp":1721709303635,"user_tz":360,"elapsed":1741,"user":{"displayName":"Angel Alejandro Maldonado Ramírez","userId":"05170948916545730550"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["class JaxMLPClassifier():\n","  def __init__(self, units, epochs=10, lr=0.01, mr=0.9, binary=True, n_classes=2, activation='relu', seed=0, batch_size=-1):\n","    self.key = random.key(seed)\n","    self.epochs = epochs\n","    self.lr = lr\n","    self.mr = mr # Momentum rate\n","    self.W = dict()\n","    self.batch_size = batch_size\n","    if activation == 'relu':\n","      self.activation = nn.relu\n","    elif activation == 'sigmoid':\n","      self.activation = nn.sigmoid\n","    else:\n","      self.activation = nn.tanh\n","\n","    if binary:\n","      self.units = units + [1]\n","    else:\n","      self.units = units + [n_classes]\n","\n","  def forward(self, W, X):\n","    n_layers = len(self.units)\n","    output = X\n","    for i in range(n_layers-1):\n","      #W = W[i]\n","      z = jnp.dot(output, jnp.transpose(W[i]))\n","      output = self.activation(z)\n","    z = jnp.dot(output, jnp.transpose(W[n_layers-1]))\n","    output = nn.sigmoid(z)\n","    return output\n","\n","  def predict(self, X):\n","    n_layers = len(self.units)\n","    output = X\n","    for i in range(n_layers-1):\n","      #W = W[i]\n","      z = jnp.dot(output, jnp.transpose(self.W[i]))\n","      output = self.activation(z)\n","    z = jnp.dot(output, jnp.transpose(self.W[n_layers-1]))\n","    output = nn.sigmoid(z)\n","    return output\n","\n","  def loss(self, W, X, y):\n","    yp = self.forward(W, X)\n","    #print(\"yp: \", jnp.min(yp))\n","    #print(\"y: \", y)\n","    #l = jnp.sum(jnp.pow(yp - y, 2))/y.shape[0]\n","    l = jnp.log(yp) * y + jnp.log(1-yp) * (1 - y) # entropia cruzada\n","    #print(\"min losses:\", jnp.max(l))\n","    #print(\"max losses:\", jnp.min(l))\n","    ls = -jnp.sum(l)/y.shape[0]\n","    return ls\n","\n","  def basic_update_step(self, W, grad_w):\n","    n_layers = len(self.units)\n","    for i in range(n_layers):\n","          W[i] = W[i] - self.lr*grad_w[i]\n","    return W\n","\n","  def momentum_update_step(self, W, grad_w, momentum_w):\n","    n_layers = len(self.units)\n","    for i in range(n_layers):\n","      momentum_w[i] = self.mr*momentum_w[i] + self.lr*W[i]\n","      W[i] = W[i] - momentum_w[i]\n","    return W, momentum_w\n","\n","  def rmsprop_update_step(self, W, grad_w, momentum_w):\n","    n_layers = len(self.units)\n","    for i in range(n_layers):\n","      momentum_w[i] = (1-self.mr)*W[i]*W[i] + self.mr*momentum_w[i]*momentum_w[i]\n","      W[i] = W[i] - self.lr / jnp.sqrt(momentum_w[i] + 0.001)*W[i]\n","    return W, momentum_w\n","\n","  def fit(self, X, y):\n","    n_features = X.shape[1]\n","    n_samples = X.shape[0]\n","    n_layers = len(self.units) # +1 para tomar en cuenta la capa de salida\n","\n","    # Creamos las matrices de pesos.\n","    keys = random.split(self.key, n_layers)\n","    W = dict()\n","    momentum = dict()\n","    for i in range(n_layers):\n","      n_units = self.units[i]\n","      W[i] = random.normal(keys[i], (n_units, n_features))\n","      momentum[i] = jnp.zeros_like(W[i])\n","      n_features = self.units[i]\n","\n","    # calculamos el gradiente y calculamos en cada batch\n","    #val_grad_loss = jit(value_and_grad(self.loss, 0))\n","    val_grad_loss = value_and_grad(self.loss, 0)\n","\n","    # Entrenamos la red\n","    X_p = lax.slice(X, (0,0), (self.batch_size,X.shape[1]))\n","    y_p = lax.slice(y, (0,), (self.batch_size,))\n","    loss_val, grad_val = val_grad_loss(W, X_p, y_p)\n","    print(f\"Initial loss: {loss_val}\")\n","    for ep in range(self.epochs):\n","      if self.batch_size == -1:\n","        # Calcular gradiente\n","        loss_val, grad_w = val_grad_loss(W, X, y)\n","        print(f\"Epoch: {ep} - Loss: {loss_val}\")\n","        #print(\"Grad: \", grad_w)\n","\n","        # Actualizar pesos\n","        #W = self.basic_update_step(W, grad_w)\n","        #W, momentum = self.momentum_update_step(W, grad_w, momentum)\n","        W, momentum = self.rmsprop_update_step(W, grad_w, momentum)\n","        #for i in range(n_layers):\n","          #W[i] = W[i] - self.lr*grad_w[i]\n","      else:\n","        n_batches = int(jnp.floor(y.shape[0]/self.batch_size))\n","        #print(n_batches)\n","        avg_loss = 0\n","        for n in range(n_batches-1):\n","          i0 = n*self.batch_size\n","          i1 = (n+1)*self.batch_size\n","          #print(i0)\n","          #print(i1)\n","          X_p = lax.slice(X, (i0,0), (i1, X.shape[1]))\n","          y_p = lax.slice(y, (i0,), (i1,))\n","          loss_val, grad_w = val_grad_loss(W, X_p, y_p)\n","          avg_loss += loss_val\n","          W, momentum = self.rmsprop_update_step(W, grad_w, momentum)\n","          #W, momentum = self.momentum_update_step(W, grad_w, momentum)\n","          #W = self.basic_update_step(W, grad_w)\n","          #for i in range(n_layers):\n","            #W[i] = W[i] - self.lr*grad_w[i]\n","\n","        print(f\"Epoch: {ep} - Loss: {avg_loss/n_batches}\")\n","    # Guardamos pesos\n","    self.W = W"],"metadata":{"id":"2d9_xfk4fHU1","executionInfo":{"status":"ok","timestamp":1721711879759,"user_tz":360,"elapsed":239,"user":{"displayName":"Angel Alejandro Maldonado Ramírez","userId":"05170948916545730550"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["from sklearn.datasets import load_breast_cancer\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score"],"metadata":{"id":"QzYf57gq0sc7","executionInfo":{"status":"ok","timestamp":1721709550212,"user_tz":360,"elapsed":1622,"user":{"displayName":"Angel Alejandro Maldonado Ramírez","userId":"05170948916545730550"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Cargamos el dataset\n","X, y = load_breast_cancer(return_X_y=True)\n","scaler = StandardScaler()\n","scaler.fit(X)\n","X_norm = scaler.transform(X)\n","X_jax = jnp.array(X_norm)\n","y_jax = jnp.array(y)"],"metadata":{"id":"JAGImsFB1ZCb","executionInfo":{"status":"ok","timestamp":1721711882842,"user_tz":360,"elapsed":204,"user":{"displayName":"Angel Alejandro Maldonado Ramírez","userId":"05170948916545730550"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["jax_model = JaxMLPClassifier([4,8,4], lr=0.001, mr=0.95, epochs=15, activation='tanh', seed=1, batch_size=32)\n","jax_model.fit(X_jax,y_jax)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OAIDC04s1meC","executionInfo":{"status":"ok","timestamp":1721712002303,"user_tz":360,"elapsed":4519,"user":{"displayName":"Angel Alejandro Maldonado Ramírez","userId":"05170948916545730550"}},"outputId":"0c3c684f-85fb-4bb3-af83-c04ff30af6e8"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Initial loss: 22.615942001342773\n","Epoch: 0 - Loss: 25.5786190032959\n","Epoch: 1 - Loss: 24.96795082092285\n","Epoch: 2 - Loss: 24.306941986083984\n","Epoch: 3 - Loss: 23.592178344726562\n","Epoch: 4 - Loss: 22.898921966552734\n","Epoch: 5 - Loss: 22.32330894470215\n","Epoch: 6 - Loss: 21.851078033447266\n","Epoch: 7 - Loss: 21.459163665771484\n","Epoch: 8 - Loss: 21.157258987426758\n","Epoch: 9 - Loss: 20.94194984436035\n","Epoch: 10 - Loss: 20.80376434326172\n","Epoch: 11 - Loss: 20.734617233276367\n","Epoch: 12 - Loss: 20.72124671936035\n","Epoch: 13 - Loss: 20.74492645263672\n","Epoch: 14 - Loss: 20.784385681152344\n"]}]},{"cell_type":"code","source":["yp_jax = jax_model.predict(X_jax)\n","yp = np.array(yp_jax.tolist())\n","preds = np.where(yp>0.5, 1, 0)\n","accuracy_score(y, preds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VPenmJ6o2o88","executionInfo":{"status":"ok","timestamp":1721712006538,"user_tz":360,"elapsed":194,"user":{"displayName":"Angel Alejandro Maldonado Ramírez","userId":"05170948916545730550"}},"outputId":"5d31e96a-b392-4a0d-d73c-ad0ccabd5b9c"},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7434094903339191"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":[],"metadata":{"id":"cjdvQlYLCg-Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Siguientes pasos:\n","\n","* Haciendo pruebas con RMSProp y Momentum vimos que la red converge más rápido al valor de error mínimo que estaba sacando.\n","* Faltaría ver que tal se comporta Adam."],"metadata":{"id":"sEtkmjYEDepH"}},{"cell_type":"code","source":[],"metadata":{"id":"JNuBuSEwD0cd"},"execution_count":null,"outputs":[]}]}
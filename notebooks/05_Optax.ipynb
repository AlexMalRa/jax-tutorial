{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNzDCE0K5A9FH7EDn00UglE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"2m-BCdlpeKax"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["# Usando Optax\n","\n","\n","* En este notebook nos enfocaremos en Optax. La librería para hacer más fácil la optimización en Jax."],"metadata":{"id":"_YK179_5eRHd"}},{"cell_type":"code","source":["# Importamos librerias\n","from jax import numpy as jnp\n","from jax import random, nn, lax\n","import jax\n","import optax\n","import numpy as np"],"metadata":{"id":"dUmB3IqLeeiV","executionInfo":{"status":"ok","timestamp":1724308166375,"user_tz":360,"elapsed":227,"user":{"displayName":"Angel Alejandro Maldonado Ramírez","userId":"05170948916545730550"}}},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":["## Cargamos datos"],"metadata":{"id":"MdA_3Kqljtbx"}},{"cell_type":"code","source":["from sklearn.datasets import load_breast_cancer\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score"],"metadata":{"id":"QzYf57gq0sc7","executionInfo":{"status":"ok","timestamp":1724304658751,"user_tz":360,"elapsed":602,"user":{"displayName":"Angel Alejandro Maldonado Ramírez","userId":"05170948916545730550"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Cargamos el dataset\n","X, y = load_breast_cancer(return_X_y=True)\n","scaler = StandardScaler()\n","scaler.fit(X)\n","X_norm = scaler.transform(X)\n","X_jax = jnp.array(X_norm)\n","y_jax = jnp.array(y)"],"metadata":{"id":"JAGImsFB1ZCb","executionInfo":{"status":"ok","timestamp":1724304664711,"user_tz":360,"elapsed":1282,"user":{"displayName":"Angel Alejandro Maldonado Ramírez","userId":"05170948916545730550"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["y_jax"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eCreyFzdwWfK","executionInfo":{"status":"ok","timestamp":1724307830993,"user_tz":360,"elapsed":4,"user":{"displayName":"Angel Alejandro Maldonado Ramírez","userId":"05170948916545730550"}},"outputId":"1e92d148-6afc-44f9-fbe2-5df9558dd9fd"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n","       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n","       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n","       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n","       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n","       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n","       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n","       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n","       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n","       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n","       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n","       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n","       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n","       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n","       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n","       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n","       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1],      dtype=int32)"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["dataset_size, input_dim = X_jax.shape\n","BATCH_SIZE = 16\n","EPOCHS = 5"],"metadata":{"id":"cjdvQlYLCg-Q","executionInfo":{"status":"ok","timestamp":1724308450844,"user_tz":360,"elapsed":215,"user":{"displayName":"Angel Alejandro Maldonado Ramírez","userId":"05170948916545730550"}}},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":["## Definimos arquitectura"],"metadata":{"id":"qRYn1nyWkeN_"}},{"cell_type":"code","source":["key = random.key(10)\n","keys = random.split(key, 4) # vamos a usar 4 capas: input, hidden1, hidden2, output"],"metadata":{"id":"KMV4SY9akurl","executionInfo":{"status":"ok","timestamp":1724308451811,"user_tz":360,"elapsed":1,"user":{"displayName":"Angel Alejandro Maldonado Ramírez","userId":"05170948916545730550"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["# Definimos los pesos\n","params = {'input_layer': random.normal(shape=[input_dim, 16], key=keys[0]),\n","          'hidden_layer1': random.normal(shape=[16, 8], key=keys[1]),\n","          'hidden_layer2': random.normal(shape=[8, 4], key=keys[2]),\n","          'output_layer': random.normal(shape=[4, 1], key=keys[3])}"],"metadata":{"id":"omGL7fNqkd4P","executionInfo":{"status":"ok","timestamp":1724308452023,"user_tz":360,"elapsed":1,"user":{"displayName":"Angel Alejandro Maldonado Ramírez","userId":"05170948916545730550"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["# Definimos la red\n","def net(x: jnp.array, params: optax.Params) -> jnp.array:\n","  y = jnp.dot(x, params['input_layer'])\n","  y = nn.tanh(y)\n","  y = jnp.dot(y, params['hidden_layer1'])\n","  y = nn.tanh(y)\n","  y = jnp.dot(y, params['hidden_layer2'])\n","  y = nn.tanh(y)\n","  y = jnp.dot(y, params['output_layer'])\n","  y = nn.sigmoid(y)\n","\n","  return y"],"metadata":{"id":"QPF8iGCOmDOl","executionInfo":{"status":"ok","timestamp":1724308452241,"user_tz":360,"elapsed":1,"user":{"displayName":"Angel Alejandro Maldonado Ramírez","userId":"05170948916545730550"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["# Definimos función de pérdida\n","def loss(params: optax.Params, batch: jnp.array, labels: jnp.array) -> jnp.array:\n","  y_hat = net(batch, params)\n","  loss_values = optax.losses.sigmoid_binary_cross_entropy(y_hat, labels).sum(axis=-1)\n","\n","  return loss_values.mean()"],"metadata":{"id":"scMA96iOnJsQ","executionInfo":{"status":"ok","timestamp":1724308452454,"user_tz":360,"elapsed":3,"user":{"displayName":"Angel Alejandro Maldonado Ramírez","userId":"05170948916545730550"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["# Definimos función de entrenamiento\n","def fit(params: optax.Params, data: jnp.array, labels: jnp.array, optimizer: optax.GradientTransformation)->optax.Params:\n","  # Inicializamos el optimizador (en el caso de Adam por ejemplo, es el momento)\n","  opt_state = optimizer.init(params)\n","\n","  # Definimos una función para aplicar en cada paso\n","  @jax.jit\n","  def step(params, opt_state, batch, labels):\n","    # Calculamos gradientes y pérdidas\n","    loss_value, grads = jax.value_and_grad(loss)(params, batch, labels)\n","\n","    # Calculamos la actualización a los parámetros (Me regresa el valor que le debo de sumar a los gradientes)\n","    updates, opt_state = optimizer.update(grads, opt_state, params)\n","\n","    # Actualizamos parámetros\n","    params = optax.apply_updates(params, updates)\n","\n","    return params, opt_state, loss_value\n","\n","  steps = dataset_size // BATCH_SIZE\n","  for epoch in range(EPOCHS):\n","    print(f\"Epoch {epoch}\")\n","    for s in range(steps):\n","      batch = lax.slice_in_dim(data, s*BATCH_SIZE, BATCH_SIZE*(s+1), axis=0)\n","      batch_labels = lax.slice_in_dim(labels, s*BATCH_SIZE, BATCH_SIZE*(s+1), axis=0)\n","      params, opt_state, loss_value = step(params, opt_state, batch, batch_labels)\n","      if s % 1 == 0:\n","        print(f'step {s}, loss: {loss_value}')\n","\n","  return params\n","\n"],"metadata":{"id":"9s3uQxckoOq9","executionInfo":{"status":"ok","timestamp":1724308452670,"user_tz":360,"elapsed":4,"user":{"displayName":"Angel Alejandro Maldonado Ramírez","userId":"05170948916545730550"}}},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":["## Entrenamos modelo"],"metadata":{"id":"nfw2M5agvJWA"}},{"cell_type":"code","source":["optimizer = optax.adam(learning_rate=1e-2)\n","trained_params = fit(params, X_jax, y_jax, optimizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4R7ntvDlvDN-","executionInfo":{"status":"ok","timestamp":1724308455727,"user_tz":360,"elapsed":1721,"user":{"displayName":"Angel Alejandro Maldonado Ramírez","userId":"05170948916545730550"}},"outputId":"4c180e18-26c2-4b45-e512-e3969d26d70f"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0\n","step 0, loss: 15.98946475982666\n","step 1, loss: 14.4599027633667\n","step 2, loss: 15.38520622253418\n","step 3, loss: 10.228194236755371\n","step 4, loss: 11.714997291564941\n","step 5, loss: 11.666516304016113\n","step 6, loss: 9.808555603027344\n","step 7, loss: 11.270360946655273\n","step 8, loss: 11.449634552001953\n","step 9, loss: 8.253365516662598\n","step 10, loss: 11.270712852478027\n","step 11, loss: 11.272677421569824\n","step 12, loss: 13.698443412780762\n","step 13, loss: 11.896186828613281\n","step 14, loss: 10.743557929992676\n","step 15, loss: 10.72927474975586\n","step 16, loss: 13.042450904846191\n","step 17, loss: 10.753866195678711\n","step 18, loss: 9.050983428955078\n","step 19, loss: 7.259209156036377\n","step 20, loss: 10.737532615661621\n","step 21, loss: 9.60079288482666\n","step 22, loss: 9.720134735107422\n","step 23, loss: 10.764806747436523\n","step 24, loss: 9.528870582580566\n","step 25, loss: 8.582788467407227\n","step 26, loss: 8.344059944152832\n","step 27, loss: 10.728671073913574\n","step 28, loss: 9.723578453063965\n","step 29, loss: 8.444610595703125\n","step 30, loss: 8.734343528747559\n","step 31, loss: 10.253328323364258\n","step 32, loss: 10.258469581604004\n","step 33, loss: 9.21741008758545\n","step 34, loss: 6.958468914031982\n","Epoch 1\n","step 0, loss: 14.21125316619873\n","step 1, loss: 13.510571479797363\n","step 2, loss: 13.544434547424316\n","step 3, loss: 10.151604652404785\n","step 4, loss: 11.645964622497559\n","step 5, loss: 11.54889965057373\n","step 6, loss: 9.597174644470215\n","step 7, loss: 11.19918155670166\n","step 8, loss: 11.332500457763672\n","step 9, loss: 8.403231620788574\n","step 10, loss: 11.30398178100586\n","step 11, loss: 11.305218696594238\n","step 12, loss: 13.306913375854492\n","step 13, loss: 11.701337814331055\n","step 14, loss: 10.799551010131836\n","step 15, loss: 10.78904914855957\n","step 16, loss: 12.96847915649414\n","step 17, loss: 10.75316047668457\n","step 18, loss: 8.849878311157227\n","step 19, loss: 7.131634712219238\n","step 20, loss: 10.757384300231934\n","step 21, loss: 9.55556869506836\n","step 22, loss: 9.646735191345215\n","step 23, loss: 10.794623374938965\n","step 24, loss: 9.444435119628906\n","step 25, loss: 8.497380256652832\n","step 26, loss: 8.131332397460938\n","step 27, loss: 10.741966247558594\n","step 28, loss: 9.511503219604492\n","step 29, loss: 8.35252571105957\n","step 30, loss: 8.746232986450195\n","step 31, loss: 10.233731269836426\n","step 32, loss: 10.206026077270508\n","step 33, loss: 9.115447998046875\n","step 34, loss: 6.39706563949585\n","Epoch 2\n","step 0, loss: 13.359172821044922\n","step 1, loss: 12.897441864013672\n","step 2, loss: 13.200146675109863\n","step 3, loss: 10.15031909942627\n","step 4, loss: 11.69082260131836\n","step 5, loss: 11.659656524658203\n","step 6, loss: 9.45311450958252\n","step 7, loss: 11.214570999145508\n","step 8, loss: 11.354293823242188\n","step 9, loss: 8.131425857543945\n","step 10, loss: 11.390050888061523\n","step 11, loss: 11.282190322875977\n","step 12, loss: 12.938139915466309\n","step 13, loss: 11.62183952331543\n","step 14, loss: 10.840185165405273\n","step 15, loss: 10.816072463989258\n","step 16, loss: 12.659113883972168\n","step 17, loss: 10.752222061157227\n","step 18, loss: 8.816461563110352\n","step 19, loss: 7.104738712310791\n","step 20, loss: 10.8263578414917\n","step 21, loss: 9.548860549926758\n","step 22, loss: 9.512812614440918\n","step 23, loss: 10.789382934570312\n","step 24, loss: 9.52703857421875\n","step 25, loss: 8.50908088684082\n","step 26, loss: 7.952894687652588\n","step 27, loss: 10.781977653503418\n","step 28, loss: 9.49515151977539\n","step 29, loss: 8.108342170715332\n","step 30, loss: 8.775166511535645\n","step 31, loss: 10.225482940673828\n","step 32, loss: 10.165916442871094\n","step 33, loss: 8.878640174865723\n","step 34, loss: 5.881058216094971\n","Epoch 3\n","step 0, loss: 12.961888313293457\n","step 1, loss: 12.61965274810791\n","step 2, loss: 13.112500190734863\n","step 3, loss: 10.187419891357422\n","step 4, loss: 11.718290328979492\n","step 5, loss: 11.673263549804688\n","step 6, loss: 9.389397621154785\n","step 7, loss: 11.273317337036133\n","step 8, loss: 11.369543075561523\n","step 9, loss: 7.983064651489258\n","step 10, loss: 11.4072847366333\n","step 11, loss: 11.298789024353027\n","step 12, loss: 12.754729270935059\n","step 13, loss: 11.703855514526367\n","step 14, loss: 10.849166870117188\n","step 15, loss: 10.843116760253906\n","step 16, loss: 12.69604206085205\n","step 17, loss: 10.778175354003906\n","step 18, loss: 8.740103721618652\n","step 19, loss: 7.074279308319092\n","step 20, loss: 10.842610359191895\n","step 21, loss: 9.54348087310791\n","step 22, loss: 9.489961624145508\n","step 23, loss: 10.796976089477539\n","step 24, loss: 9.409090995788574\n","step 25, loss: 8.508305549621582\n","step 26, loss: 7.942483901977539\n","step 27, loss: 10.789867401123047\n","step 28, loss: 9.463360786437988\n","step 29, loss: 7.936061859130859\n","step 30, loss: 8.73363971710205\n","step 31, loss: 10.242341995239258\n","step 32, loss: 10.166751861572266\n","step 33, loss: 8.80055046081543\n","step 34, loss: 5.616981029510498\n","Epoch 4\n","step 0, loss: 12.70748233795166\n","step 1, loss: 12.534934997558594\n","step 2, loss: 12.967392921447754\n","step 3, loss: 10.176390647888184\n","step 4, loss: 11.671183586120605\n","step 5, loss: 11.698450088500977\n","step 6, loss: 9.3515043258667\n","step 7, loss: 11.287458419799805\n","step 8, loss: 11.387271881103516\n","step 9, loss: 7.888150215148926\n","step 10, loss: 11.410848617553711\n","step 11, loss: 11.326285362243652\n","step 12, loss: 12.535391807556152\n","step 13, loss: 11.677953720092773\n","step 14, loss: 10.850448608398438\n","step 15, loss: 10.838095664978027\n","step 16, loss: 12.6188325881958\n","step 17, loss: 10.752446174621582\n","step 18, loss: 8.62409496307373\n","step 19, loss: 7.083868503570557\n","step 20, loss: 10.824761390686035\n","step 21, loss: 9.54135799407959\n","step 22, loss: 9.453274726867676\n","step 23, loss: 10.780158996582031\n","step 24, loss: 9.415513038635254\n","step 25, loss: 8.498477935791016\n","step 26, loss: 7.91180419921875\n","step 27, loss: 10.752821922302246\n","step 28, loss: 9.406231880187988\n","step 29, loss: 7.935544013977051\n","step 30, loss: 8.707877159118652\n","step 31, loss: 10.215413093566895\n","step 32, loss: 10.130887031555176\n","step 33, loss: 8.71437931060791\n","step 34, loss: 5.668535232543945\n"]}]},{"cell_type":"code","source":["# Evaluación\n","yp_jax = net(X_jax, trained_params)\n","yp = np.array(yp_jax.tolist())\n","preds = np.where(yp>0.5, 1, 0)\n","accuracy_score(y, preds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3EHmnXiExYsp","executionInfo":{"status":"ok","timestamp":1724308466330,"user_tz":360,"elapsed":235,"user":{"displayName":"Angel Alejandro Maldonado Ramírez","userId":"05170948916545730550"}},"outputId":"b2a662f3-69f8-4b90-9c72-56c975cc3157"},"execution_count":63,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9314586994727593"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":[],"metadata":{"id":"JNuBuSEwD0cd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Conclusiones\n","\n","* Ayuda mucho la librería de optax para no preocuparse por la implementación de la pérdida y de la actualización de gradientes.\n","* Resalto mucho la importancia de la arquitectura de la red neuronal.\n","* De los hiperparametros, de los que más afecto fue el batch size, mientras más pequeño parece que funcinó mejor."],"metadata":{"id":"_tX1ObRty3rX"}},{"cell_type":"code","source":[],"metadata":{"id":"s_o9NUQCzOQJ"},"execution_count":null,"outputs":[]}]}